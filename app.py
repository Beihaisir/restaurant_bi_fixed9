from __future__ import annotations

import io
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

from utils.io import read_any_table, read_raw_noheader
from utils.rules import load_rules_xlsx, match_categories, Rule
from utils.transform import build_fact_tables

st.set_page_config(page_title="é¤é¥®ç»è¥åˆ†æç³»ç»Ÿ", layout="wide")


@dataclass
class StoreBundle:
    store_id: str
    daily: Optional[pd.DataFrame]
    dish: Optional[pd.DataFrame]
    pay: Optional[pd.DataFrame]


DAILY_MUST = ["é—¨åº—ä»£ç ", "é—¨åº—åç§°", "æ—¥æœŸ"]
DISH_MUST = ["åˆ›å»ºæ—¶é—´", "èœå“åç§°", "POSé”€å”®å•å·"]
PAY_MUST = ["POSé”€å”®å•å·", "æ”¯ä»˜ç±»å‹", "æ€»é‡‘é¢"]


def _as_bytes(uploaded) -> bytes:
    return uploaded.getvalue()


def _norm_colset(cols) -> set:
    out = set()
    for c in cols:
        s = str(c).strip().replace(" ", "").replace("\u3000", "")
        out.add(s)
    return out


def detect_table_kind(file_bytes: bytes, filename: str) -> Tuple[str, Optional[str]]:
    """
    Returns (kind, store_id) where kind in {"daily","dish","pay","unknown"}.
    Robust heuristics for real-world exported Excel.
    """
    raw = read_raw_noheader(file_bytes, filename)

    # store id
    store_id = None
    for r in range(min(20, len(raw))):
        for cell in raw.iloc[r].astype(str).tolist():
            if "å¯¼å‡ºäºº" in str(cell):
                import re

                m = re.search(r"å¯¼å‡ºäºº[:ï¼š]\s*(\d+)", str(cell))
                if m:
                    store_id = m.group(1)
                    break
        if store_id:
            break

    top_text = " ".join(raw.head(5).astype(str).fillna("").values.flatten().tolist())
    if "æ—¥é”€å”®æŠ¥è¡¨" in top_text:
        return "daily", store_id

    df_dish, _ = read_any_table(file_bytes, filename, DISH_MUST)
    if {"POSé”€å”®å•å·", "èœå“åç§°", "åˆ›å»ºæ—¶é—´"}.issubset(_norm_colset(df_dish.columns)):
        return "dish", store_id

    df_pay, _ = read_any_table(file_bytes, filename, PAY_MUST)
    if {"POSé”€å”®å•å·", "æ”¯ä»˜ç±»å‹"}.issubset(_norm_colset(df_pay.columns)):
        return "pay", store_id

    df_daily, _ = read_any_table(file_bytes, filename, DAILY_MUST)
    cols_daily = _norm_colset(df_daily.columns)
    if ("å«ç¨é”€å”®é¢" in cols_daily) or ("å®¢æµé‡" in cols_daily) or ({"é—¨åº—ä»£ç ", "é—¨åº—åç§°", "æ—¥æœŸ"}.issubset(cols_daily)):
        return "daily", store_id

    return "unknown", store_id


@st.cache_data(show_spinner=False)
def parse_uploaded(files: List, rule_file) -> Tuple[List[StoreBundle], List[str], List[Rule]]:
    rules: List[Rule] = []
    if rule_file is not None:
        rules = load_rules_xlsx(io.BytesIO(_as_bytes(rule_file)))

    bundles: Dict[str, StoreBundle] = {}
    warnings: List[str] = []

    def upsert(store_id: str) -> StoreBundle:
        if store_id not in bundles:
            bundles[store_id] = StoreBundle(store_id=store_id, daily=None, dish=None, pay=None)
        return bundles[store_id]

    for f in files:
        b = _as_bytes(f)
        name = f.name
        kind, store_id = detect_table_kind(b, name)
        if store_id is None:
            store_id = "UNKNOWN"

        if kind == "daily":
            df, _ = read_any_table(b, name, DAILY_MUST)
            upsert(store_id).daily = df
        elif kind == "dish":
            df, _ = read_any_table(b, name, DISH_MUST)
            upsert(store_id).dish = df
        elif kind == "pay":
            df, _ = read_any_table(b, name, PAY_MUST)
            upsert(store_id).pay = df
        else:
            warnings.append(f"æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹ï¼š{name}ï¼ˆå·²è·³è¿‡ï¼‰")

    out = list(bundles.values())
    out.sort(key=lambda x: x.store_id)
    return out, warnings, rules


def fmt_money(x: float) -> str:
    try:
        return f"Â¥{x:,.2f}"
    except Exception:
        return "â€”"


def halfhour_options(min_dt: pd.Timestamp, max_dt: pd.Timestamp) -> List[pd.Timestamp]:
    if pd.isna(min_dt) or pd.isna(max_dt):
        return []
    start = min_dt.floor("30min")
    end = max_dt.ceil("30min")
    return list(pd.date_range(start, end, freq="30min"))


def apply_time_filter(df: pd.DataFrame, col: str, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    x = df.copy()
    if col not in x.columns:
        return x
    x[col] = pd.to_datetime(x[col], errors="coerce")
    return x[(x[col] >= start) & (x[col] <= end)].copy()


def _base_items(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    if "ç±»å‹_norm" in df.columns:
        return df[df["ç±»å‹_norm"].isin(["èœå“", "å¥—é¤"])].copy()
    # fallback: contains
    return df[df["ç±»å‹"].astype(str).str.contains("èœå“|å¥—é¤", na=False)].copy()


def main() -> None:
    st.title("ğŸ½ï¸ é¤é¥®ç»è¥åˆ†æç³»ç»Ÿï¼ˆè¿é”è§†è§’ Â· è‘£äº‹/è‚¡ä¸œ Â· é—¨åº—åº—é•¿ï¼‰")

    with st.sidebar:
        st.header("æ•°æ®è¾“å…¥")
        rule_file = st.file_uploader("ä¸Šä¼ ï¼šåˆ†ç±»è§„åˆ™æ¨¡æ¿ï¼ˆxlsxï¼ŒSheet=è§„åˆ™è¡¨ï¼‰", type=["xlsx"], accept_multiple_files=False)
        files = st.file_uploader(
            "ä¸Šä¼ ï¼šä¸‰ç±»æŠ¥è¡¨ï¼ˆå¯å¤šé—¨åº—ã€å¤šæ–‡ä»¶ï¼›æ”¯æŒ xls/xlsx/csvï¼‰",
            type=["xls", "xlsx", "csv"],
            accept_multiple_files=True,
        )
        st.caption("å£å¾„ï¼šæ—¶é—´æœ€å°30åˆ†é’Ÿï¼›â€œåŠ xxâ€ä¸ºå•åŠ ï¼ˆåŠ å¤šå®é™¤å¤–ï¼‰ï¼›å¤©éº»é¢å¹¶å…¥ç»†é¢ï¼›â€œæ ‡å‡†â€ä»…ç»Ÿè®¡ä¸ºã€å¥—é¤ã€‘çš„æ ‡å‡†è¡Œã€‚")

    if not files:
        st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æŠ¥è¡¨æ–‡ä»¶ã€‚")
        return

    bundles, warnings, rules = parse_uploaded(files, rule_file)

    if warnings:
        with st.expander("âš ï¸ æ–‡ä»¶è¯†åˆ«è­¦å‘Š", expanded=False):
            for w in warnings:
                st.warning(w)

    analyzable = [b for b in bundles if b.dish is not None and b.pay is not None and b.daily is not None and b.store_id != "UNKNOWN"]
    missing = [b for b in bundles if b not in analyzable]

    if missing:
        with st.expander("âš ï¸ ç¼ºè¡¨é—¨åº—ï¼ˆä¸è¿›å…¥åˆ†æï¼‰", expanded=False):
            st.dataframe(
                pd.DataFrame(
                    [
                        {
                            "store_id": b.store_id,
                            "æœ‰æ—¥é”€å”®": b.daily is not None,
                            "æœ‰èœå“æ˜ç»†": b.dish is not None,
                            "æœ‰æ”¯ä»˜æ˜ç»†": b.pay is not None,
                        }
                        for b in missing
                    ]
                ),
                use_container_width=True,
            )

    if not analyzable:
        st.error("æ²¡æœ‰â€œä¸‰è¡¨é½å…¨â€çš„é—¨åº—ï¼Œæ— æ³•åˆ†æã€‚")
        return

    store_ids = [b.store_id for b in analyzable]
    sel_stores = st.multiselect("é€‰æ‹©é—¨åº—ï¼ˆæ”¯æŒå¤šåº—å¯¹æ¯”ï¼‰", options=store_ids, default=store_ids[:1])
    if not sel_stores:
        st.stop()

    facts_by_store: Dict[str, Dict[str, pd.DataFrame]] = {}
    for b in analyzable:
        if b.store_id in sel_stores:
            facts_by_store[b.store_id] = build_fact_tables(b.dish, b.pay, rules, b.store_id)

    all_orders = pd.concat([facts_by_store[s]["fact_orders"] for s in sel_stores], ignore_index=True)
    min_dt = all_orders["order_time"].min()
    max_dt = all_orders["order_time"].max()
    opts = halfhour_options(min_dt, max_dt)
    if not opts:
        st.error("æ— æ³•ä»æ•°æ®ä¸­è§£æåˆ›å»ºæ—¶é—´ã€‚")
        return

    c1, c2 = st.columns(2)
    with c1:
        start = st.selectbox("å¼€å§‹æ—¶é—´ï¼ˆ30åˆ†é’Ÿç²’åº¦ï¼‰", options=opts, index=0, format_func=lambda x: x.strftime("%Y-%m-%d %H:%M"))
    with c2:
        end = st.selectbox("ç»“æŸæ—¶é—´ï¼ˆ30åˆ†é’Ÿç²’åº¦ï¼‰", options=opts, index=len(opts) - 1, format_func=lambda x: x.strftime("%Y-%m-%d %H:%M"))

    if start > end:
        st.error("å¼€å§‹æ—¶é—´ä¸èƒ½æ™šäºç»“æŸæ—¶é—´ã€‚")
        return

    filtered: Dict[str, Dict[str, pd.DataFrame]] = {}
    for sid in sel_stores:
        f = facts_by_store[sid]
        filtered[sid] = {
            "items_main": apply_time_filter(f["fact_items_main"], "åˆ›å»ºæ—¶é—´", start, end),
            "items_add": apply_time_filter(f["fact_items_add"], "created_at", start, end),
            "pay": apply_time_filter(f["fact_pay"], "order_time", start, end),
            "orders": apply_time_filter(f["fact_orders"], "order_time", start, end),
        }

    tabs = st.tabs(
        [
            "â‘  è‘£äº‹/è‚¡ä¸œæ€»è§ˆ",
            "â‘¡ é—¨åº—å¯¹æ¯”",
            "â‘¢ è§„æ ¼",
            "â‘£ å“ç±»ç»“æ„",
            "â‘¤ å•åŠ åˆ†æ",
            "â‘¥ æ”¯ä»˜æ¸ é“",
            "â‘¦ é€€æ¬¾/å¼‚å¸¸ä¸å¯¹è´¦",
            "â‘§ æœªåˆ†ç±»æ± ï¼ˆå¯å¯¼å‡ºï¼‰",
            "â‘¨ æ˜ç»†å¯¼å‡º",
            "â‘© æ—¶æ®µçƒ­åŠ›å›¾",
        ]
    )

    # â‘  æ€»è§ˆï¼ˆè§„æ¨¡ã€æ•ˆç‡ã€çˆ†å“/é•¿å°¾ã€å•åŠ ç»“æ„ï¼‰
    with tabs[0]:
        st.subheader("è‘£äº‹/è‚¡ä¸œè§†è§’ï¼šè§„æ¨¡ã€æ•ˆç‡ã€ç»“æ„ã€é£é™©")

        rows = []
        for sid in sel_stores:
            o = filtered[sid]["orders"]
            p = filtered[sid]["pay"]
            orders = int(o["POSé”€å”®å•å·"].nunique()) if not o.empty else 0
            rows.append(
                {
                    "store_id": sid,
                    "è®¢å•æ•°": orders,
                    "èœå“é”€é‡": float(o["dish_qty"].sum()) if not o.empty else 0.0,
                    "èœå“åº”æ”¶(ä¼˜æƒ å)": float(o["net_amount"].sum()) if not o.empty else 0.0,
                    "æ”¯ä»˜å®æ”¶": float(p["æ€»é‡‘é¢"].sum()) if not p.empty else 0.0,
                    "é€€æ¬¾å•å æ¯”": float(o["has_refund"].mean()) if not o.empty else 0.0,
                    "å®¢å•(åº”æ”¶/è®¢å•)": (float(o["net_amount"].sum()) / orders) if orders else np.nan,
                }
            )
        dfk = pd.DataFrame(rows)

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("é€‰ä¸­é—¨åº—è®¢å•æ•°", int(dfk["è®¢å•æ•°"].sum()))
        k2.metric("é€‰ä¸­é—¨åº—èœå“é”€é‡", f"{dfk['èœå“é”€é‡'].sum():,.0f}")
        k3.metric("é€‰ä¸­é—¨åº—èœå“åº”æ”¶(ä¼˜æƒ å)", fmt_money(dfk["èœå“åº”æ”¶(ä¼˜æƒ å)"].sum()))
        k4.metric("é€‰ä¸­é—¨åº—æ”¯ä»˜å®æ”¶", fmt_money(dfk["æ”¯ä»˜å®æ”¶"].sum()))
        st.dataframe(dfk, use_container_width=True)

        # åŠå°æ—¶è¶‹åŠ¿ + å³°å€¼
        oall = pd.concat([filtered[s]["orders"] for s in sel_stores], ignore_index=True)
        if not oall.empty:
            oall["bucket"] = oall["order_time"].dt.floor("30min")
            trend = oall.groupby("bucket", as_index=False).agg(
                è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"),
                èœå“åº”æ”¶=("net_amount", "sum"),
            ).sort_values("bucket")
            st.line_chart(trend.set_index("bucket")[["è®¢å•æ•°", "èœå“åº”æ”¶"]])
            peak = trend.sort_values("è®¢å•æ•°", ascending=False).head(10)
            st.markdown("**å³°å€¼æ—¶æ®µ Top10ï¼ˆæŒ‰è®¢å•æ•°ï¼‰**")
            st.dataframe(peak, use_container_width=True)

        # Top èœå“ + å¸•ç´¯æ‰˜
        main_all = pd.concat([filtered[s]["items_main"] for s in sel_stores], ignore_index=True)
        base_items = _base_items(main_all)
        if not base_items.empty:
            top_rev = (
                base_items.groupby("èœå“åç§°", as_index=False)
                .agg(åº”æ”¶=("ä¼˜æƒ åå°è®¡ä»·æ ¼", "sum"), é”€é‡=("èœå“æ•°é‡", "sum"), è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"))
                .sort_values(["åº”æ”¶", "é”€é‡"], ascending=False)
                .head(20)
            )
            st.markdown("### Top20 èœå“ï¼ˆæŒ‰åº”æ”¶æ’åºï¼‰")
            st.dataframe(top_rev, use_container_width=True)
            st.bar_chart(top_rev.set_index("èœå“åç§°")[["åº”æ”¶"]])

            dish_rev = base_items.groupby("èœå“åç§°", as_index=False).agg(åº”æ”¶=("ä¼˜æƒ åå°è®¡ä»·æ ¼", "sum")).sort_values("åº”æ”¶", ascending=False)
            dish_rev["ç´¯è®¡åº”æ”¶"] = dish_rev["åº”æ”¶"].cumsum()
            total_rev = dish_rev["åº”æ”¶"].sum()
            dish_rev["ç´¯è®¡å æ¯”"] = dish_rev["ç´¯è®¡åº”æ”¶"] / total_rev if total_rev else 0
            n80 = int((dish_rev["ç´¯è®¡å æ¯”"] <= 0.8).sum() + 1) if total_rev else 0
            st.markdown("### çˆ†å“/é•¿å°¾ï¼ˆå¸•ç´¯æ‰˜ï¼‰")
            st.write(f"è¾¾åˆ° **80%åº”æ”¶** éœ€è¦çš„èœå“æ•°ï¼š**{n80}** / æ€»èœå“æ•° {len(dish_rev)}")
            st.dataframe(dish_rev.head(50), use_container_width=True)

        # Top å•åŠ 
        add_all = pd.concat([filtered[s]["items_add"] for s in sel_stores], ignore_index=True)
        if not add_all.empty:
            top_add = (
                add_all.groupby("add_display", as_index=False)
                .agg(å•åŠ é‡‘é¢=("amount", "sum"), é”€é‡=("qty", "sum"), è®¢å•æ•°=("order_id", "nunique"))
                .sort_values(["å•åŠ é‡‘é¢", "é”€é‡"], ascending=False)
                .head(20)
            )
            st.markdown("### Top20 å•åŠ ï¼ˆæŒ‰å•åŠ é‡‘é¢æ’åºï¼‰")
            st.dataframe(top_add, use_container_width=True)
            st.bar_chart(top_add.set_index("add_display")[["å•åŠ é‡‘é¢"]])

    # â‘¡ é—¨åº—å¯¹æ¯”
    with tabs[1]:
        st.subheader("é—¨åº—å¯¹æ¯”ï¼šåŒå£å¾„çœ‹å·®å¼‚ï¼ˆåº—é•¿/åŒºåŸŸç»ç†/æ€»éƒ¨ï¼‰")
        rows = []
        for sid in sel_stores:
            o = filtered[sid]["orders"]
            p = filtered[sid]["pay"]
            orders = int(o["POSé”€å”®å•å·"].nunique()) if not o.empty else 0
            net = float(o["net_amount"].sum()) if not o.empty else 0.0
            paid = float(p["æ€»é‡‘é¢"].sum()) if not p.empty else 0.0
            rows.append(
                {
                    "store_id": sid,
                    "è®¢å•æ•°": orders,
                    "åº”æ”¶(ä¼˜æƒ å)": net,
                    "å®æ”¶": paid,
                    "åº”æ”¶-å®æ”¶å·®å¼‚": net - paid,
                    "å®¢å•(åº”æ”¶/è®¢å•)": (net / orders) if orders else np.nan,
                }
            )
        df = pd.DataFrame(rows).sort_values("åº”æ”¶(ä¼˜æƒ å)", ascending=False)
        st.dataframe(df, use_container_width=True)
        st.bar_chart(df.set_index("store_id")[["åº”æ”¶(ä¼˜æƒ å)", "å®æ”¶"]])
        c1, c2 = st.columns(2)
        with c1:
            st.bar_chart(df.set_index("store_id")[["åº”æ”¶-å®æ”¶å·®å¼‚"]])
        with c2:
            st.bar_chart(df.set_index("store_id")[["å®¢å•(åº”æ”¶/è®¢å•)"]])

    # â‘¢ è§„æ ¼ï¼ˆå«æ ‡å‡†=å¥—é¤æ ‡å‡†ï¼‰
    with tabs[2]:
        st.subheader("è§„æ ¼ï¼šä¸»é£Ÿç»“æ„ï¼ˆå«â€œæ ‡å‡†â€=å¥—é¤æ ‡å‡†ï¼‰")
        st.caption("è§„æ ¼åˆ†å¸ƒåªç»Ÿè®¡ï¼šæ ‡å‡† / å®½é¢ / ç»†é¢(å«å¤©éº»é¢) / ç±³é¥­ / å®½ç²‰(å«ç²‰) / æ— éœ€ä¸»é£Ÿï¼›â€œæ ‡å‡†â€ä»…æ¥æºäº ç±»å‹=å¥—é¤ çš„æ ‡å‡†è¡Œã€‚")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            m = filtered[sid]["items_main"]
            if m.empty:
                st.info("æ— æ•°æ®")
                continue

            base = _base_items(m)
            spec_base = base[base["spec_norm"].notna()].copy()
            if spec_base.empty:
                st.info("è¯¥æ—¶é—´èŒƒå›´å†…æ²¡æœ‰å‘½ä¸­è§„æ ¼ç™½åå•çš„æ•°æ®ã€‚")
                continue

            spec = (
                spec_base.groupby("spec_norm", as_index=False)
                .agg(é”€é‡=("èœå“æ•°é‡", "sum"), åº”æ”¶=("ä¼˜æƒ åå°è®¡ä»·æ ¼", "sum"), è¡Œæ•°=("èœå“åç§°", "count"), è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"))
                .sort_values(["é”€é‡", "åº”æ”¶"], ascending=False)
            )
            spec["é”€é‡å æ¯”"] = spec["é”€é‡"] / spec["é”€é‡"].sum() if spec["é”€é‡"].sum() else 0
            spec["åº”æ”¶å æ¯”"] = spec["åº”æ”¶"] / spec["åº”æ”¶"].sum() if spec["åº”æ”¶"].sum() else 0
            st.dataframe(spec, use_container_width=True)
            c1, c2 = st.columns(2)
            with c1:
                st.bar_chart(spec.set_index("spec_norm")[["é”€é‡"]])
            with c2:
                st.bar_chart(spec.set_index("spec_norm")[["åº”æ”¶"]])

            spec_base["bucket"] = spec_base["åˆ›å»ºæ—¶é—´"].dt.floor("30min")
            top_specs = spec["spec_norm"].head(5).tolist()
            pivot = (
                spec_base[spec_base["spec_norm"].isin(top_specs)]
                .groupby(["bucket", "spec_norm"], as_index=False)
                .agg(é”€é‡=("èœå“æ•°é‡", "sum"))
            )
            if not pivot.empty:
                piv = pivot.pivot(index="bucket", columns="spec_norm", values="é”€é‡").fillna(0).sort_index()
                st.line_chart(piv)

    # â‘£ å“ç±»ç»“æ„
    with tabs[3]:
        st.subheader("å“ç±»ç»“æ„ï¼šè§„åˆ™æ¨¡æ¿å‘½ä¸­ï¼ˆå¤šæ ‡ç­¾ï¼‰")
        st.caption("ä¸€ä¸ªèœå“å¯å‘½ä¸­å¤šä¸ªåˆ†ç±»ï¼Œå‘½ä¸­å³å„è®¡ä¸€æ¬¡ï¼›æœªå‘½ä¸­è¿›å…¥æœªåˆ†ç±»æ± ã€‚")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            m = filtered[sid]["items_main"]
            if m.empty:
                st.info("æ— æ•°æ®")
                continue

            exploded = m.copy().explode("categories")
            exploded["categories"] = exploded["categories"].fillna("æœªåˆ†ç±»")

            cat = (
                exploded.groupby("categories", as_index=False)
                .agg(é”€é‡=("èœå“æ•°é‡", "sum"), åº”æ”¶=("ä¼˜æƒ åå°è®¡ä»·æ ¼", "sum"), èœå“è¡Œæ•°=("èœå“åç§°", "count"))
                .sort_values("åº”æ”¶", ascending=False)
            )

            st.dataframe(cat, use_container_width=True)
            st.bar_chart(cat.set_index("categories")[["åº”æ”¶"]])

            topn = st.slider(f"TopN èœå“ï¼ˆé—¨åº— {sid}ï¼‰", min_value=5, max_value=50, value=20, step=5, key=f"topn_{sid}")
            cats = ["å…¨éƒ¨"] + sorted(exploded["categories"].dropna().unique().tolist())
            sel_cat = st.selectbox(f"é€‰æ‹©åˆ†ç±»ï¼ˆé—¨åº— {sid}ï¼‰", options=cats, key=f"selcat_{sid}")
            view = exploded if sel_cat == "å…¨éƒ¨" else exploded[exploded["categories"] == sel_cat]
            top_items = (
                view.groupby("èœå“åç§°", as_index=False)
                .agg(åº”æ”¶=("ä¼˜æƒ åå°è®¡ä»·æ ¼", "sum"), é”€é‡=("èœå“æ•°é‡", "sum"), è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"))
                .sort_values(["åº”æ”¶", "é”€é‡"], ascending=False)
                .head(topn)
            )
            st.dataframe(top_items, use_container_width=True)

    # â‘¤ å•åŠ åˆ†æ
    with tabs[4]:
        st.subheader("å•åŠ åˆ†æï¼šåŠ æ–™å¸¦æ¥çš„ç»“æ„ä¸å®¢å•æå‡ï¼ˆä¸ä¸»èœä¸¥æ ¼éš”ç¦»ï¼‰")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            a = filtered[sid]["items_add"]
            if a.empty:
                st.info("æ— å•åŠ è®°å½•")
                continue

            add = (
                a.groupby("add_display", as_index=False)
                .agg(é”€é‡=("qty", "sum"), å•åŠ é‡‘é¢=("amount", "sum"), è®¢å•æ•°=("order_id", "nunique"), æ¥æº=("source", lambda s: ",".join(sorted(set(map(str, s))))))
                .sort_values(["å•åŠ é‡‘é¢", "é”€é‡"], ascending=False)
            )
            st.dataframe(add, use_container_width=True)
            st.bar_chart(add.set_index("add_display")[["å•åŠ é‡‘é¢"]])

            orders = filtered[sid]["orders"]
            add_orders = int(a["order_id"].nunique())
            total_orders = int(orders["POSé”€å”®å•å·"].nunique()) if not orders.empty else 0
            st.metric("å•åŠ æ¸—é€ç‡ï¼ˆå«å•åŠ è®¢å•/æ€»è®¢å•ï¼‰", f"{(add_orders / total_orders * 100) if total_orders else 0:.1f}%")

            # å•åŠ å¯¹å®¢å•æå‡ï¼ˆè®¢å•å±‚é¢ï¼‰
            if not orders.empty:
                add_set = set(a["order_id"].dropna().astype(str).tolist())
                o2 = orders.copy()
                o2["has_add"] = o2["POSé”€å”®å•å·"].astype(str).isin(add_set)
                grp = o2.groupby("has_add", as_index=False).agg(è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"), åº”æ”¶=("net_amount", "sum"))
                grp["å®¢å•(åº”æ”¶/è®¢å•)"] = grp["åº”æ”¶"] / grp["è®¢å•æ•°"].replace(0, np.nan)
                st.markdown("**æœ‰å•åŠ  vs æ— å•åŠ ï¼ˆå®¢å•æå‡ï¼‰**")
                st.dataframe(grp, use_container_width=True)

    # â‘¥ æ”¯ä»˜æ¸ é“
    with tabs[5]:
        st.subheader("æ”¯ä»˜æ¸ é“ï¼šæ¸ é“ç»“æ„ã€å›¢è´­æ¸—é€ã€æ··åˆæ”¯ä»˜")
        st.caption("æ’åºæŒ‰å®æ”¶é™åºï¼Œå…¶æ¬¡æŒ‰æ”¯ä»˜ç¬”æ•°ã€‚è‹¥å®æ”¶=0ï¼Œä¼šå±•ç¤ºæ”¯ä»˜æ˜ç»†å‰50è¡Œä¾¿äºæ’æŸ¥ï¼ˆé‡‘é¢åˆ—å/æ ¼å¼/æ—¶é—´èŒƒå›´ï¼‰ã€‚")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            p = filtered[sid]["pay"]
            if p.empty:
                st.warning("æ— æ”¯ä»˜æ•°æ®ï¼ˆè¯¥é—¨åº—åœ¨ç­›é€‰æ—¶é—´èŒƒå›´å†…æ”¯ä»˜è¡¨æœªå…³è”åˆ°ä»»ä½•è®¢å•ï¼Œæˆ–æ”¯ä»˜è¡¨æœªè¢«æ­£ç¡®è¯†åˆ«ï¼‰")
                continue

            if float(p["æ€»é‡‘é¢"].sum()) == 0.0:
                st.warning("å·²è¯»åˆ°æ”¯ä»˜è¡¨ï¼Œä½†æ€»é‡‘é¢è§£æä¸º 0ï¼šå¯èƒ½æ˜¯é‡‘é¢åˆ—å/æ ¼å¼ä¸ä¸€è‡´ï¼Œæˆ–è¯¥æ—¶é—´èŒƒå›´å†…æ— åŒ¹é…è®¢å•ã€‚")
                st.dataframe(p.head(50), use_container_width=True)

            pay = (
                p.groupby("æ”¯ä»˜ç±»å‹", as_index=False)
                .agg(å®æ”¶=("æ€»é‡‘é¢", "sum"), æ”¯ä»˜ç¬”æ•°=("POSé”€å”®å•å·", "count"), æ¶‰åŠè®¢å•=("POSé”€å”®å•å·", "nunique"))
                .sort_values(["å®æ”¶", "æ”¯ä»˜ç¬”æ•°"], ascending=False)
            )
            st.dataframe(pay, use_container_width=True)
            st.bar_chart(pay.set_index("æ”¯ä»˜ç±»å‹")[["å®æ”¶", "æ”¯ä»˜ç¬”æ•°"]])

            multi = p.groupby("POSé”€å”®å•å·").agg(n=("æ”¯ä»˜ç±»å‹", "nunique")).reset_index()
            mixed_rate = (multi["n"] > 1).mean() if not multi.empty else 0
            st.metric("æ··åˆæ”¯ä»˜è®¢å•å æ¯”", f"{mixed_rate * 100:.1f}%")

    # â‘¦ é€€æ¬¾/å¼‚å¸¸ä¸å¯¹è´¦ï¼ˆå·®å¼‚åˆ†è§£ï¼‰
    with tabs[6]:
        st.subheader("é€€æ¬¾/å¼‚å¸¸ä¸å¯¹è´¦ï¼šæŠ“é£é™©ã€æŠ“æ¼æŸã€æŠ“å£å¾„é—®é¢˜")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            o = filtered[sid]["orders"]
            p = filtered[sid]["pay"]
            if o.empty:
                st.info("æ— æ•°æ®")
                continue

            r = o.merge(p.groupby(["store_id", "POSé”€å”®å•å·"], as_index=False).agg(paid=("æ€»é‡‘é¢", "sum")), on=["store_id", "POSé”€å”®å•å·"], how="left")
            r["paid"] = r["paid"].fillna(0.0)
            r["diff"] = r["net_amount"] - r["paid"]

            st.caption("å¯¹è´¦å£å¾„ï¼šèœå“åº”æ”¶ï¼ˆä¼˜æƒ åå°è®¡æ±‚å’Œï¼‰ vs æ”¯ä»˜å®æ”¶ï¼ˆæ”¯ä»˜è¡¨é‡‘é¢æ±‚å’Œï¼‰ã€‚")
            st.dataframe(r.sort_values("diff", ascending=False).head(100), use_container_width=True)

            # å·®å¼‚åˆ†è§£ï¼šæŒ‰æ¸ é“/æŒ‰åŠå°æ—¶
            if not p.empty:
                pay_kind = p.groupby(["store_id", "POSé”€å”®å•å·"], as_index=False).agg(
                    paid=("æ€»é‡‘é¢", "sum"),
                    k=("æ”¯ä»˜ç±»å‹", lambda s: "æ··åˆ" if s.nunique() > 1 else str(list(s)[0])),
                )
                rr = o.merge(pay_kind, on=["store_id", "POSé”€å”®å•å·"], how="left")
                rr["paid"] = rr["paid"].fillna(0.0)
                rr["diff"] = rr["net_amount"] - rr["paid"]

                byk = (
                    rr.groupby("k", as_index=False)
                    .agg(è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"), åº”æ”¶=("net_amount", "sum"), å®æ”¶=("paid", "sum"), å·®å¼‚=("diff", "sum"))
                    .sort_values("å·®å¼‚", ascending=False)
                )
                st.markdown("**æŒ‰æ”¯ä»˜æ¸ é“åˆ†è§£ï¼ˆå·®å¼‚=åº”æ”¶-å®æ”¶ï¼‰**")
                st.dataframe(byk, use_container_width=True)
                st.bar_chart(byk.set_index("k")[["å·®å¼‚"]])

                rr["slot"] = rr["order_time"].dt.floor("30min")
                bys = (
                    rr.groupby("slot", as_index=False)
                    .agg(è®¢å•æ•°=("POSé”€å”®å•å·", "nunique"), å·®å¼‚=("diff", "sum"), åº”æ”¶=("net_amount", "sum"), å®æ”¶=("paid", "sum"))
                    .sort_values("slot")
                )
                st.markdown("**æŒ‰åŠå°æ—¶åˆ†è§£ï¼ˆå·®å¼‚è¶‹åŠ¿ï¼‰**")
                st.line_chart(bys.set_index("slot")[["å·®å¼‚", "åº”æ”¶", "å®æ”¶"]])

                st.download_button(
                    f"å¯¼å‡ºå·®å¼‚Topè®¢å•ï¼ˆ{sid}ï¼‰CSV",
                    data=rr.sort_values("diff", ascending=False).head(500).to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"å¯¹è´¦å·®å¼‚Top_{sid}.csv",
                    mime="text/csv",
                )

            refund_rate = float(o["has_refund"].mean()) if not o.empty else 0.0
            st.metric("é€€æ¬¾å•å æ¯”ï¼ˆèœå“è¡¨å­˜åœ¨POSé€€æ¬¾å•å·ï¼‰", f"{refund_rate * 100:.1f}%")

    # â‘§ æœªåˆ†ç±»æ± 
    with tabs[7]:
        st.subheader("æœªåˆ†ç±»æ± ï¼šå¯æŸ¥çœ‹ã€å¯å¯¼å‡ºï¼ˆè§„åˆ™è¿­ä»£å…¥å£ï¼‰")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            m = filtered[sid]["items_main"]
            if m.empty:
                st.info("æ— æ•°æ®")
                continue

            un = m[m["categories"].apply(lambda x: len(x) == 0)].copy()
            st.write(f"æœªåˆ†ç±»ä¸»èœè¡Œæ•°ï¼š{len(un):,}")
            st.dataframe(un[["åˆ›å»ºæ—¶é—´", "èœå“åç§°", "ç±»å‹", "è§„æ ¼åç§°", "ä¼˜æƒ åå°è®¡ä»·æ ¼", "POSé”€å”®å•å·"]].head(200), use_container_width=True)
            st.download_button(
                f"å¯¼å‡ºæœªåˆ†ç±»ä¸»èœï¼ˆ{sid}ï¼‰CSV",
                data=un.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"æœªåˆ†ç±»ä¸»èœ_{sid}.csv",
                mime="text/csv",
            )

            a = filtered[sid]["items_add"]
            if not a.empty:
                if rules:
                    a2 = a.copy()
                    a2["add_cat"] = a2["add_name"].apply(lambda x: " / ".join(match_categories(str(x), rules)) if match_categories(str(x), rules) else "")
                    un_add = a2[a2["add_cat"] == ""].copy()
                else:
                    un_add = a.copy()

                st.write(f"æœªåˆ†ç±»å•åŠ è¡Œæ•°ï¼š{len(un_add):,}")
                st.dataframe(un_add.head(200), use_container_width=True)
                st.download_button(
                    f"å¯¼å‡ºæœªåˆ†ç±»å•åŠ ï¼ˆ{sid}ï¼‰CSV",
                    data=un_add.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"æœªåˆ†ç±»å•åŠ _{sid}.csv",
                    mime="text/csv",
                )

    # â‘¨ æ˜ç»†å¯¼å‡º
    with tabs[8]:
        st.subheader("æ˜ç»†å¯¼å‡ºï¼šæ€»éƒ¨/è´¢åŠ¡/åº—é•¿äºŒæ¬¡åˆ†æ")

        for sid in sel_stores:
            st.markdown(f"#### é—¨åº— {sid}")
            m = filtered[sid]["items_main"]
            a = filtered[sid]["items_add"]
            p = filtered[sid]["pay"]
            o = filtered[sid]["orders"]

            if not m.empty:
                st.download_button(
                    f"å¯¼å‡ºèœå“æ˜ç»†-è¿‡æ»¤åï¼ˆ{sid}ï¼‰CSV",
                    data=m.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"èœå“æ˜ç»†_è¿‡æ»¤å_{sid}.csv",
                    mime="text/csv",
                )
            if not a.empty:
                st.download_button(
                    f"å¯¼å‡ºå•åŠ æ˜ç»†-è¿‡æ»¤åï¼ˆ{sid}ï¼‰CSV",
                    data=a.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"å•åŠ æ˜ç»†_è¿‡æ»¤å_{sid}.csv",
                    mime="text/csv",
                )
            if not p.empty:
                st.download_button(
                    f"å¯¼å‡ºæ”¯ä»˜æ˜ç»†-è¿‡æ»¤åï¼ˆ{sid}ï¼‰CSV",
                    data=p.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"æ”¯ä»˜æ˜ç»†_è¿‡æ»¤å_{sid}.csv",
                    mime="text/csv",
                )
            if not o.empty:
                st.download_button(
                    f"å¯¼å‡ºè®¢å•æ±‡æ€»-è¿‡æ»¤åï¼ˆ{sid}ï¼‰CSV",
                    data=o.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"è®¢å•æ±‡æ€»_è¿‡æ»¤å_{sid}.csv",
                    mime="text/csv",
                )

    # â‘© æ—¶æ®µçƒ­åŠ›å›¾
    with tabs[9]:
        st.subheader("æ—¶æ®µçƒ­åŠ›å›¾ï¼ˆ30åˆ†é’Ÿç²’åº¦ï¼‰ï¼šå³°è°·ã€æ’ç­ã€å¤‡è´§ã€æ¸ é“åŠ¨ä½œ")
        st.caption("è¡Œ=æ—¥æœŸï¼Œåˆ—=åŠå°æ—¶ï¼›å¯é€‰æ‹©æŒ‡æ ‡ï¼›æ”¯æŒé€‰ä¸­é—¨åº—æ±‡æ€»æˆ–æŒ‰é—¨åº—åˆ†åˆ«æŸ¥çœ‹ã€‚")

        metric = st.selectbox(
            "é€‰æ‹©æŒ‡æ ‡",
            options=["è®¢å•æ•°", "åº”æ”¶(ä¼˜æƒ å)", "å®æ”¶", "å®¢å•(åº”æ”¶/è®¢å•)", "å•åŠ æ¸—é€ç‡(å«å•åŠ è®¢å•/æ€»è®¢å•)"],
            index=0,
        )
        scope = st.radio("èŒƒå›´", options=["é€‰ä¸­é—¨åº—æ±‡æ€»", "æŒ‰é—¨åº—åˆ†åˆ«çœ‹"], horizontal=True)

        def _build_heat(o_df: pd.DataFrame, p_df: pd.DataFrame, a_df: pd.DataFrame) -> Optional[pd.DataFrame]:
            if o_df is None or o_df.empty:
                return None

            o = o_df.copy()
            o["date"] = o["order_time"].dt.date
            o["slot"] = o["order_time"].dt.floor("30min").dt.strftime("%H:%M")
            grp = o.groupby(["date", "slot"], as_index=False).agg(orders=("POSé”€å”®å•å·", "nunique"), net=("net_amount", "sum"))

            if p_df is not None and not p_df.empty:
                p = p_df.copy()
                p["date"] = p["order_time"].dt.date
                p["slot"] = p["order_time"].dt.floor("30min").dt.strftime("%H:%M")
                paid = p.groupby(["date", "slot"], as_index=False).agg(paid=("æ€»é‡‘é¢", "sum"))
                grp = grp.merge(paid, on=["date", "slot"], how="left")
            grp["paid"] = grp.get("paid", 0).fillna(0.0)

            if a_df is not None and not a_df.empty:
                a = a_df.copy()
                a["date"] = a["created_at"].dt.date
                a["slot"] = a["created_at"].dt.floor("30min").dt.strftime("%H:%M")
                add_o = a.groupby(["date", "slot"], as_index=False).agg(add_orders=("order_id", "nunique"))
                grp = grp.merge(add_o, on=["date", "slot"], how="left")
            grp["add_orders"] = grp.get("add_orders", 0).fillna(0)

            grp["aov"] = grp["net"] / grp["orders"].replace(0, np.nan)
            grp["add_rate"] = grp["add_orders"] / grp["orders"].replace(0, np.nan)
            return grp

        def _render_heat(df: Optional[pd.DataFrame]) -> None:
            if df is None or df.empty:
                st.info("æ— å¯ç”¨æ•°æ®")
                return

            if metric == "è®¢å•æ•°":
                mat = df.pivot(index="date", columns="slot", values="orders").fillna(0).astype(int)
            elif metric == "åº”æ”¶(ä¼˜æƒ å)":
                mat = df.pivot(index="date", columns="slot", values="net").fillna(0.0)
            elif metric == "å®æ”¶":
                mat = df.pivot(index="date", columns="slot", values="paid").fillna(0.0)
            elif metric == "å®¢å•(åº”æ”¶/è®¢å•)":
                mat = df.pivot(index="date", columns="slot", values="aov")
            else:
                mat = df.pivot(index="date", columns="slot", values="add_rate")

            cols = sorted(mat.columns, key=lambda x: (int(x.split(":")[0]), int(x.split(":")[1])))
            mat = mat[cols]

            st.dataframe(mat.style.background_gradient(axis=None), use_container_width=True)

            flat = df.copy()
            if metric == "è®¢å•æ•°":
                flat["v"] = flat["orders"]
            elif metric == "åº”æ”¶(ä¼˜æƒ å)":
                flat["v"] = flat["net"]
            elif metric == "å®æ”¶":
                flat["v"] = flat["paid"]
            elif metric == "å®¢å•(åº”æ”¶/è®¢å•)":
                flat["v"] = flat["aov"]
            else:
                flat["v"] = flat["add_rate"]

            top = flat.sort_values("v", ascending=False).head(10)[["date", "slot", "v", "orders", "net", "paid", "add_rate"]]
            st.markdown("**Top10 æ—¶æ®µï¼ˆæŒ‰å½“å‰æŒ‡æ ‡ï¼‰**")
            st.dataframe(top, use_container_width=True)

        if scope == "é€‰ä¸­é—¨åº—æ±‡æ€»":
            oall = pd.concat([filtered[s]["orders"] for s in sel_stores], ignore_index=True)
            pall = pd.concat([filtered[s]["pay"] for s in sel_stores], ignore_index=True)
            aall = pd.concat([filtered[s]["items_add"] for s in sel_stores], ignore_index=True)
            _render_heat(_build_heat(oall, pall, aall))
        else:
            for sid in sel_stores:
                st.markdown(f"#### é—¨åº— {sid}")
                _render_heat(_build_heat(filtered[sid]["orders"], filtered[sid]["pay"], filtered[sid]["items_add"]))


if __name__ == "__main__":
    main()
